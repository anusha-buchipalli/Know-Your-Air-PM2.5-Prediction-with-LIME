# -*- coding: utf-8 -*-
"""InternshipAir-Pollution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dvwKcztx4_Hv4bzRpCt-7ujcICf4XXfE
"""

!nvidia-smi

#"We have commented out this section as the dataset has already been downloaded."
'''
import opendatasets as od

od.download(
    "https://www.kaggle.com/datasets/adarshrouniyar/air-pollution-image-dataset-from-india-and-nepal")
'''

from pathlib import Path

current_directory = Path.cwd()
print("Current Working Directory:", current_directory)

project_root = Path("/Users/DK19/Downloads/anusha")
data_root = project_root / "archive" / "Dataset_for_AQI_Classification" / "Dataset_for_AQI_Classification"
image_root = project_root / "archive" / "Air Pollution Image Dataset" / "Air Pollution Image Dataset" / "Combined_Dataset" / "All_img"

print("Data root:", data_root)
print("Image root:", image_root)

import pandas as pd
df_train = pd.read_csv('/content/drive/MyDrive/Dataset_for_AQI_Classification/train_data.csv')
df_train

import matplotlib.pyplot as plt
import seaborn as sns
# Assuming AQI_Class column contains categories like 'a_Good', 'b_Moderate', etc.
# You can create a new column with the modified category labels

# Define a mapping dictionary to map the old labels to the new labels
category_mapping = {
    'a_Good': 'Good',
    'b_Moderate': 'Moderate',
    'c_Unhealthy_for_Sensitive_Groups': 'USG',
    'd_Unhealthy' : 'Unhealthy',
    'e_Very_Unhealthy' : 'Very Unhealthy',
    'f_Severe' : 'Severe'
}

# Apply the mapping to create a new column with modified category labels
df_train['Modified_AQI_Class'] = df_train['AQI_Class'].map(category_mapping)

# Now, you can plot the count of modified categories
plt.figure(figsize=(12,6))
plt.title('Class Distribution of Training Dataset')
custom_order = ['Good', 'Moderate', 'USG', 'Unhealthy', 'Very Unhealthy', 'Severe']
sns.countplot(data=df_train,x='Modified_AQI_Class', order=custom_order, palette='Set2')

import numpy as np
min_pm2_lable = np.min(df_train['PM2.5'])
max_pm2_lable = np.max(df_train['PM2.5'])
mean_pm2_lable = np.mean(df_train['PM2.5'])
stdev_pm2_lable = np.std(df_train['PM2.5'])
severe = np.count_nonzero(df_train['PM2.5'] > 250.5)
good = np.count_nonzero(df_train['PM2.5'] < 12.1)
moderate = np.count_nonzero((df_train['PM2.5'] > 12) & (df_train['PM2.5'] < 35.5))
sensitive = np.count_nonzero((df_train['PM2.5'] > 35.4) & (df_train['PM2.5'] < 55.5))
unhealthy = np.count_nonzero((df_train['PM2.5'] > 55.4) & (df_train['PM2.5'] < 150.5))
vunhealthy = np.count_nonzero((df_train['PM2.5'] > 150.4) & (df_train['PM2.5'] < 250.5))
print('Minimum label value for PM2.5 :', min_pm2_lable)
print('Maximum label value for PM2.5 :', max_pm2_lable)
print('Average label value for PM2.5 :', mean_pm2_lable)
print('Standard Deviation label value for PM2.5 :', stdev_pm2_lable)
print('Severe class based on PM2.5 value :', severe)
print('Very Unhealthy class based on PM2.5 value :', vunhealthy)
print('Unhealthy class based on PM2.5 value :', unhealthy)
print('Sensitive class based on PM2.5 value :', sensitive)
print('Moderate class based on PM2.5 value :', moderate)
print('Good class based on PM2.5 value :', good)

import statsmodels.api as sm
df_pm25 = df_train['PM2.5'].sort_values()
df_pm25 = df_pm25.reset_index(drop=True)
x = df_pm25.index
y = df_pm25
plt.xlabel('Index')
plt.ylabel('PM2.5 Value')
plt.title('Data Linearity of PM2.5 for Training')
plt.scatter(x, y)
plt.show()
# Fit the linear regression model
cX = sm.add_constant(x)
model = sm.OLS(y, cX).fit()
print(model.summary())

df_val = pd.read_csv('/content/drive/MyDrive/Dataset_for_AQI_Classification/val_data.csv')
df_val

category_mapping = {
    'a_Good': 'Good',
    'b_Moderate': 'Moderate',
    'c_Unhealthy_for_Sensitive_Groups': 'USG',
    'd_Unhealthy' : 'Unhealthy',
    'e_Very_Unhealthy' : 'Very Unhealthy',
    'f_Severe' : 'Severe'
}

# Apply the mapping to create a new column with modified category labels
df_val['Modified_AQI_Class'] = df_val['AQI_Class'].map(category_mapping)

# Now, you can plot the count of modified categories
plt.figure(figsize=(12,6))
plt.title('Class Distribution of Validation Dataset')
custom_order = ['Good', 'Moderate', 'USG', 'Unhealthy', 'Very Unhealthy', 'Severe']
sns.countplot(data=df_val,x='Modified_AQI_Class', order=custom_order, palette='Set2')

df_test = pd.read_csv('/content/drive/MyDrive/Dataset_for_AQI_Classification/testing_data.csv')
df_test
min_pm2_lable = np.min(df_test['PM2.5'])
max_pm2_lable = np.max(df_test['PM2.5'])
mean_pm2_lable = np.mean(df_test['PM2.5'])
stdev_pm2_lable = np.std(df_test['PM2.5'])
severe = np.count_nonzero(df_test['PM2.5'] > 250.5)
good = np.count_nonzero(df_test['PM2.5'] < 12.1)
moderate = np.count_nonzero((df_test['PM2.5'] > 12) & (df_test['PM2.5'] < 35.5))
sensitive = np.count_nonzero((df_test['PM2.5'] > 35.4) & (df_test['PM2.5'] < 55.5))
unhealthy = np.count_nonzero((df_test['PM2.5'] > 55.4) & (df_test['PM2.5'] < 150.5))
vunhealthy = np.count_nonzero((df_test['PM2.5'] > 150.4) & (df_test['PM2.5'] < 250.5))
print('Minimum label value for PM2.5 :', min_pm2_lable)
print('Maximum label value for PM2.5 :', max_pm2_lable)
print('Average label value for PM2.5 :', mean_pm2_lable)
print('Standard Deviation label value for PM2.5 :', stdev_pm2_lable)
print('Severe class based on PM2.5 value :', severe)
print('Very Unhealthy class based on PM2.5 value :', vunhealthy)
print('Unhealthy class based on PM2.5 value :', unhealthy)
print('Sensitive class based on PM2.5 value :', sensitive)
print('Moderate class based on PM2.5 value :', moderate)
print('Good class based on PM2.5 value :', good)

df_pm25_test = df_test['PM2.5'].sort_values()
df_pm25_test = df_pm25_test.reset_index(drop=True)
x = df_pm25_test.index
y = df_pm25_test
plt.xlabel('Index')
plt.ylabel('PM2.5 Value')
plt.title('Data Linearity of PM2.5 for Testing')
plt.scatter(x, y)
plt.show()
# Fit the linear regression model
cX = sm.add_constant(x)
model = sm.OLS(y, cX).fit()
print(model.summary())

# Commented out IPython magic to ensure Python compatibility.
#Import all necessary library
import sys
import numpy as np

from typing import Dict, Optional, Tuple
from pathlib import Path

import math
import pandas as pd

import tensorflow as tf
from tensorflow import keras

import seaborn as sns
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn import preprocessing
from sklearn.model_selection import train_test_split

from tensorflow.keras import backend #Keras version 2.1.6
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate, LeakyReLU, Input, Conv2D, MaxPooling2D, BatchNormalization, Add

from tensorflow.keras import layers

from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing import image
#from PIL import Image

from sklearn.metrics import r2_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix


def build_x(path, y, df, target_size=(224, 224), normalize=True):
    base_path = Path(path)
    images = []
    for filename in df['Filename']:
        img_path = base_path / filename
        img = image.load_img(img_path, target_size=target_size)
        img = image.img_to_array(img)
        if normalize:
            img = img / 255.0
        images.append(img)
    return np.array(images)


# %matplotlib inline

# Preparing image data for Validation
y_val = df_val[['AQI','PM2.5','PM10','O3','CO','SO2','NO2']].copy()
val_img = build_x('/content/drive/MyDrive/archive (2)/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/All_img/',y_val, df_val)
val_img.shape

# Preparing image data for Testing
y_test = df_test[['AQI','PM2.5','PM10','O3','CO','SO2','NO2']].copy()
test_img = build_x('/content/drive/MyDrive/archive (2)/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/All_img/',y_test, df_test)
test_img.shape

#Preparing label data for Validation
y_val = df_val[['AQI','PM2.5','PM10','O3','CO','SO2','NO2']].copy()
y_val

#Preparing label data for Testing
y_test = df_test[['AQI','PM2.5','PM10','O3','CO','SO2','NO2']].copy()
y_test

#This function takes the path to an RGB image file as input, reads the image using Keras library and converts it to a NumPy array.
#You can then use this array as input to your machine learning model.

def build_x(path, y, df):
    train_img = []
    for i in range(len(y)):
        img = image.load_img(path + df['Filename'][i])
        img = image.img_to_array(img)
        img = img / 255
        train_img.append(img)

    x = np.array(train_img)
    return x

#Preparing label data for Training
y_train = df_train[['AQI','PM2.5','PM10','O3','CO','SO2','NO2']].copy()
train_img = build_x('/content/drive/MyDrive/archive (2)/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/All_img/',y_train, df_train)
train_img.shape

import os
import numpy as np
from tensorflow.keras.preprocessing import image

def build_x(path, y, df):
    train_img = []
    for i in range(len(y)):
        # Safely join folder + filename
        img_path = os.path.join(path, df['Filename'].iloc[i])

        # Load image
        img = image.load_img(img_path, target_size=(224, 224))  # resize optional
        img = image.img_to_array(img)
        img = img / 255.0  # normalize

        train_img.append(img)

    x = np.array(train_img)
    return x

import pandas as pd
from sklearn.model_selection import train_test_split
import os

base_path = '/content/drive/MyDrive/archive (2)/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset'

data = []
for label, folder in enumerate(['Clean_Air', 'Polluted_Air']):  # 0 = clean, 1 = polluted
    folder_path = os.path.join(base_path, folder)
    for filename in os.listdir(folder_path):
        data.append((filename, label))

df = pd.DataFrame(data, columns=['Filename', 'Label'])
print(df.head())

